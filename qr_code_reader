import cv2
import numpy as np
import matplotlib.pyplot as plt
# ------------------------------------------------------------------------------

pathname = "/Users/laina/Documents/VT/ComputerVision/hw2/"
qr_a = "QR_A.png"
qr_b = "QR_B.png"
qr_c = "QR_C.png"
qr_d = "QR_D.png"
qr_e = "QR_E.png"
templatemade = "templatemade.png"

# Reads in images and convert to grayscale
input1 = cv2.imread(pathname + qr_a, 0)
input2 = cv2.imread(pathname + qr_b, 0)
input3 = cv2.imread(pathname + qr_c, 0)
input4 = cv2.imread(pathname + qr_d, 0)
input5 = cv2.imread(pathname + qr_e, 0)

# making og
original1 = cv2.imread(pathname + qr_a)
original2 = cv2.imread(pathname + qr_b)
original3 = cv2.imread(pathname + qr_c)
original4 = cv2.imread(pathname + qr_d)
original5 = cv2.imread(pathname + qr_e)
# ------------------------------------------------------------------------------

gray = cv2.imread(pathname + qr_a, 0) # letter needs to change depending on which image
img = input1 # number needs to change depending on which image
original = original1 # number needs to change depending on which image
t_img = "tempimage.png"
template = cv2.imread(pathname + t_img, 0)

imagetoroi = input1
ogtoroi = original1

# create template for matching
blur = cv2.GaussianBlur(imagetoroi, (9, 9), 0)
sharpen_kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
sharpen = cv2.filter2D(blur, -1, sharpen_kernel)

# Threshold and morph close
thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
close = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)

# Find contours and filter using threshold area
cnts = cv2.findContours(close, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
cnts = cnts[0] if len(cnts) == 2 else cnts[1]
location = []
for c in cnts:
p = cv2.arcLength(c, True)
approx = cv2.approxPolyDP(c, 0.04 * p, True)
x, y, w, h = cv2.boundingRect(approx)
area = cv2.contourArea(c)
ar = w / float(h)
if len(approx) == 4 and area > 1000 and (ar > .85 and ar < 1.3):
ROI = ogtoroi[y:y + h, x:x + w]
cv2.imwrite('ROI.png', ROI)
print('Found Location')
location.append([x,y])
print((x, y), (x + w, y + h))
cv2.imshow('image_original', original)
imgroi = ROI.copy()
old_image_height, old_image_width, channels = imgroi.shape

# add padding to img
new_image_width = 128
new_image_height = 128
color = (255, 255, 255)
imgresult = np.full((new_image_height, new_image_width, channels), color, dtype=np.uint8)

# compute center offset
x_center = (new_image_width - old_image_width) // 2
y_center = (new_image_height - old_image_height) // 2
# copy image into center of result image
imgresult[y_center:y_center + old_image_height, x_center:x_center + old_image_width] =
imgroi

# view result
cv2.imshow("generated_template", imgresult)
cv2.imwrite(pathname + templatemade, imgresult)


# find and select the three marker locations
templateimg = cv2.imread(pathname + templatemade, 0)
res = cv2.matchTemplate(gray, templateimg, cv2.TM_CCOEFF_NORMED)
cv2.imshow('res',res)

threshold = 0.8
loc = np.where(res >= threshold)
for pt in zip(loc[1], loc[0]):
cv2.rectangle(original, pt, (pt[0] + w, pt[1] + h), (255, 0, 0), 2) # best working

## ANOTHER ATTEMP AT PARSING THROUGH THE MULTIPLE BOXES

cv2.imshow('resultscan', original)
#cv2.waitKey()
print('Done')
# ------------------------------------------------------------------------------
# create proper affine transformation and transformed image
# making images to input into affine method
imgaff1 = cv2.imread(pathname + qr_a)
imgaff2 = cv2.imread(pathname + qr_b)
imgaff3 = cv2.imread(pathname + qr_c)
imgaff4 = cv2.imread(pathname + qr_d)
imgaff5 = cv2.imread(pathname + qr_e)
# POINTS: [[50,50],[250,50],[50,250]]
# manually need to change the code to run per image.
# IMAGES TO USE: imgaff1, imgaff2, imgaff3, imgaff4, imgaff5
col = 300
row = 300
# Define the 3 pairs of corresponding points
num1 = location[0]
num2 = location[2]
num3 = location[1]
input_pts1 = np.float32([num1, num2, num3]) # this works if you run imageA above as well.
# input_pts1 = np.float32([[43,532],[267,297],[39,303]]) # if you don't run imageA
input_pts2 = np.float32([[522,1085],[897, 678],[499, 691]])
input_pts3 = np.float32([[70,434],[302,62],[65,117]])
input_pts4 = np.float32([[180, 1227],[1282, 235],[235, 180]])
input_pts5 = np.float32([[358, 564],[585, 330],[354, 333]])
output_pts = np.float32([[50,50],[250,50],[50,250]])
M = cv2.getAffineTransform(input_pts1, output_pts) # change input_ptsX here if not imageA
# Apply the affine transformation using cv2.warpAffine()
dst = cv2.warpAffine(original, M, (col,row))
# write affine image to a disk
# cv2.imwrite(pathname + 'aff1.png', dst)
# cv2.imwrite(pathname + 'aff2.png', dst)
# cv2.imwrite(pathname + 'aff3.png', dst)
# cv2.imwrite(pathname + 'aff4.png', dst)
# cv2.imwrite(pathname + 'aff5.png', dst)
# plt.imshow(original)
plt.imshow(dst)
plt.show()
cv2.waitKey(0)# write affine image to a disk
# cv2.imwrite(pathname + 'aff1.png', dst)
# cv2.imwrite(pathname + 'aff2.png', dst)
# cv2.imwrite(pathname + 'aff3.png', dst)
# cv2.imwrite(pathname + 'aff4.png', dst)
# cv2.imwrite(pathname + 'aff5.png', dst)
# plt.imshow(original)
plt.imshow(dst)
plt.show()
cv2.waitKey(0)
